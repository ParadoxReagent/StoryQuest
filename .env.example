# StoryQuest Environment Variables
# Copy this file to .env and fill in your values

# ===========================================
# LLM Provider Configuration
# ===========================================
# Choose one: ollama, openai, anthropic
LLM_PROVIDER=ollama

# ===========================================
# Ollama (Local LLM)
# ===========================================
# If using Ollama running on your host machine
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.2:3b

# ===========================================
# OpenAI (Cloud LLM)
# ===========================================
# Uncomment and set if using OpenAI
# OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_MODEL=gpt-4o-mini

# ===========================================
# Anthropic (Cloud LLM)
# ===========================================
# Uncomment and set if using Anthropic
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# ===========================================
# Safety & Content Moderation
# ===========================================
USE_ENHANCED_FILTER=true
USE_MODERATION_API=false
LOG_VIOLATIONS=true
ENABLE_RATE_LIMITING=true

# Optional: OpenAI Moderation API (requires OpenAI API key)
# USE_MODERATION_API=true
# OPENAI_API_KEY=sk-your-openai-api-key-here

# ===========================================
# Database Configuration
# ===========================================
# SQLite (default for Docker)
DATABASE_URL=sqlite:///./data/storyquest.db

# PostgreSQL (optional - for production)
# DATABASE_URL=postgresql://user:password@postgres:5432/storyquest
